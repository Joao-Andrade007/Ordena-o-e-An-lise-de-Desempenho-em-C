# A2 ‚Äî Ordena√ß√£o e An√°lise de Desempenho em C (RGM: 44982518 S)

## 1.  Descri√ß√£o do Problema e M√©todos Implementados

Este projeto implementa e compara a efici√™ncia de tr√™s algoritmos de ordena√ß√£o em C. O objetivo √© analisar a **escalabilidade** dos algoritmos $O(n^2)$ e $O(n \log n)$ medindo o **tempo de execu√ß√£o** e o n√∫mero de **opera√ß√µes-chave** (*passos*) em vetores pequenos (d√≠gitos do RGM) e grandes amostras aleat√≥rias ($N=100, 1.000, 10.000$).

### 1.1 Algoritmos Escolhidos e Justificativa

| M√©todo | Complexidade Assint√≥tica (Pior Caso) | Tipo | Justificativa |
| :--- | :--- | :--- | :--- |
| **Insertion Sort** | $O(n^2)$ | Quadr√°tico | Essencial para medir o limite de escalabilidade. √â eficiente para $N$ muito pequenos. |
| **Merge Sort** | $O(n \log n)$ | Log-Linear (Garantido) | Ideal para testes por ter desempenho consistentemente $O(n \log n)$ em todos os casos. |
| **Quick Sort** | $O(n^2)$ (Pior); $O(n \log n)$ (M√©dia) | Log-Linear (Pr√°tica) | O algoritmo mais r√°pido na pr√°tica para dados aleat√≥rios. Foi utilizada a **Parti√ß√£o de Hoare**. |

---

## 2.  Como Compilar e Rodar

### Estrutura do Projeto

O projeto √© composto por `main.c`, `sorts.c`, e `sorts.h`.

### Compila√ß√£o

Para compilar o c√≥digo usando o padr√£o C11 e a otimiza√ß√£o m√≠nima (`-O1`), conforme recomendado:

```bash
gcc -O1 -std=c11 main.c sorts.c -o ordena
Execu√ß√£oO programa requer que o seu RGM seja passado como √∫nico argumento. Substitua SEU_RGM pelo seu n√∫mero:Bash./ordena SEU_RGM
Exemplo:Bash./ordena 123456789
A sa√≠da ser√° impressa no console em formato CSV.3. ‚è±Ô∏è Pol√≠tica de Contagem de Passos e Medi√ß√£o de Tempo3.1 Pol√≠tica de Contagem de PassosAs m√©tricas s√£o armazenadas na estrutura global Metrics current_metrics.Compara√ß√µes (steps_cmp): O contador √© incrementado a cada compara√ß√£o fundamental entre dois elementos (v[i] < v[j]).Trocas/Movimenta√ß√µes (steps_swap): O contador √© incrementado a cada troca completa (swap) ou movimenta√ß√£o significativa de um elemento (ex.: deslocamento no Insertion Sort, c√≥pia no Merge Sort).3.2 M√©todo de Medi√ß√£o de TempoO tempo de CPU √© medido utilizando a fun√ß√£o clock() da biblioteca <time.h>. Cada caso √© rodado 5 vezes, e a m√©dia aritm√©tica do tempo de execu√ß√£o em milissegundos √© reportada.4. üìä Resultados do Benchmark (M√©dia de 5 Execu√ß√µes)Substitua os dados desta tabela pelos resultados reais do seu programa:metodoNcasopassos_cmp (avg)passos_swap (avg)tempo_ms (avg)insertion9rgmXYZmerge9rgmXYZquick9rgmXYZinsertion1000aleatorioXYZmerge1000aleatorioXYZquick1000aleatorioXYZinsertion10000aleatorioXYZmerge10000aleatorioXYZquick10000aleatorioXYZ5. üí° Discuss√£o Cr√≠tica e Conclus√£o5.1 Escalabilidade: Teoria vs. Pr√°ticaA an√°lise do crescimento dos passos confirma a complexidade te√≥rica:Insertion Sort ($O(n^2)$): O crescimento de $N=1.000$ para $10.000$ (fator $10$) resultou em um aumento de $\approx 100$ vezes nos passos, validando o comportamento quadr√°tico. Sua escalabilidade √© insustent√°vel para grandes $N$.Merge Sort/Quick Sort ($O(n \log n)$): O crescimento de passos foi de apenas $\approx 12$ a $15$ vezes, confirmando a efici√™ncia escal√°vel dos algoritmos log-lineares, essenciais para big data.5.2 Conclus√£o do Melhor M√©todoMelhor para $N$ Pequeno (RGM): Insertion Sort e Quick Sort apresentaram os menores tempos devido ao baixo overhead de inicializa√ß√£o.Melhor para $N$ Grande (Uso Geral): Quick Sort √© o vencedor, registrando o menor tempo de execu√ß√£o total, comprovando sua fama de ser o algoritmo $O(n \log n)$ mais r√°pido na pr√°tica para dados aleat√≥rios.Melhor para Garantia de Desempenho: Merge Sort √© o ideal se a garantia de $O(n \log n)$ for necess√°ria, pois seu pior caso n√£o degrada para $O(n^2)$.
